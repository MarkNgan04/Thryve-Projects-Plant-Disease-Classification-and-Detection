{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJWfPDTJRMwh3ym2dOT/mT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkNgan04/Thryve-Projects-Plant-Disease-Classification-and-Detection/blob/main/Thryve_Projects_Plant_Disease_Classification_and_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Setup"
      ],
      "metadata": {
        "id": "WP4ZMFGFT6Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install addict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7buobfvUTxR",
        "outputId": "c318f2b8-ea71-403b-8fe0-999ec6cf02ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from addict import Dict\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import logging"
      ],
      "metadata": {
        "id": "6lySbts5crf2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/rashikrahmanpritom/plant-disease-recognition-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YleniGGYVRBt",
        "outputId": "21244002-2409-4f51-e3ba-c5fe0d7e3ea9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./plant-disease-recognition-dataset\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "I2CNSm3Vcjbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int=42):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "uH3IyUuzVxPh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer(model:torch.nn.Module, name: str=\"SGD\", parameters:dict={}) -> torch.optim.Optimizer:\n",
        "  optimizers = {\n",
        "      \"SGD\": torch.optim.SGD,\n",
        "      \"AdamW\": torch.optim.AdamW,\n",
        "      \"Adam\": torch.optim.Adam,\n",
        "      \"RMSprop\": torch.optim.RMSprop\n",
        "  }\n",
        "\n",
        "  instance = optimizers.get(name, \"SDD\")\n",
        "  optimizer = instance(model.parameters(), **parameters)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "LtDqfF2YdMVQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scheduler(optimizer: torch.optim.Optimizer, name: str, parameters: dict):\n",
        "  schedulers = {\n",
        "        \"ReduceLROnPlateau\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        \"LambdaLR\": torch.optim.lr_scheduler.LambdaLR,\n",
        "        \"StepLR\": torch.optim.lr_scheduler.StepLR,\n",
        "        \"ExponentialLR\": torch.optim.lr_scheduler.ExponentialLR,\n",
        "        \"MultiplicativeLR\": torch.optim.lr_scheduler.MultiplicativeLR,\n",
        "        \"MultiStepLR\": torch.optim.lr_scheduler.MultiStepLR,\n",
        "  }\n",
        "\n",
        "  instance = schedulers[name]\n",
        "  scheduler = instance(optimizer, **parameters)\n",
        "  return scheduler"
      ],
      "metadata": {
        "id": "szCr-mBJfDEB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score(predictions:torch.Tensor, targets:torch.Tensor) -> torch.Tensor:\n",
        "  amount = (predictions == targets).sum()\n",
        "  accuracy = amount / targets.size(0)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "8m09ScGJPAkp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hide_spines(ax, spines=[\"top\", \"right\", \"left\", \"bottom\"]):\n",
        "    for spine in spines:\n",
        "        ax.spines[spine].set_visible(False)"
      ],
      "metadata": {
        "id": "ph40TRO5QB2R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(rows, cols, indexes, class_=0):\n",
        "    min_index = min(indexes)\n",
        "    max_index = max(indexes)\n",
        "    fig = plt.figure(figsize=(3*cols, 3*rows))\n",
        "    for i in range(*indexes):\n",
        "        item = train_dataset[i]\n",
        "        image = item.image\n",
        "        label = item.label\n",
        "\n",
        "        if label == class_:\n",
        "            ax = fig.add_subplot(rows, cols, (i - min_index)+1)\n",
        "            ax.imshow(image.permute(1, 2, 0))\n",
        "            ax.xaxis.set_visible(False)\n",
        "            ax.yaxis.set_visible(False)\n",
        "\n",
        "    fig.text(s=f\"{train_dataset.labels[class_]} leaves\", x=0.125, y=0.9, fontweight=\"bold\", fontfamily=\"serif\", fontsize=20)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "RITY7nI0QOJT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_logger(name:str=__name__, format:str=\"[%(asctime)s][%(levelname)s]: %(message)s\") -> logging.Logger:\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter(format)\n",
        "\n",
        "    file_handler = logging.FileHandler(name)\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setLevel(logging.INFO)\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    logger.propagate = False\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "id": "hbXYhvjsQPxg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Configuration"
      ],
      "metadata": {
        "id": "PqCIEnW2Qc4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Dict({\n",
        "    \"train_path\": \"../input/plant-disease-recognition-dataset/Train/Train\",\n",
        "    \"test_path\": \"../input/plant-disease-recognition-dataset/Test/Test\",\n",
        "    \"validation_path\": \"../input/plant-disease-recognition-dataset/Validation/Validation\"\n",
        "})\n",
        "\n",
        "train_config = Dict({\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"epochs\": 5,\n",
        "    \"seed\": 2021,\n",
        "    \"image_shape\": (128, 128),\n",
        "    \"image_channels\": 3,\n",
        "    \"num_workers\": 0,\n",
        "    \"batch_size\": 32,\n",
        "\n",
        "    \"augmentations\": A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        #A.Blur(p=1),\n",
        "        ToTensorV2(),\n",
        "    ]),\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"parameters\": {\n",
        "            \"lr\": 0.001,\n",
        "            \"weight_decay\": 0.01,\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"ReduceLROnPlateau\",\n",
        "        \"parameters\": {\n",
        "            \"patience\": 2,\n",
        "            \"mode\": \"min\",\n",
        "            \"factor\": 0.1,\n",
        "        }\n",
        "    }\n",
        "})\n",
        "\n",
        "\n",
        "seed_everything(train_config.seed)"
      ],
      "metadata": {
        "id": "qxlwlLgaQVOY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "GzUoy_RTYldO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDiseaseDataset(Dataset):\n",
        "    def __init__(self, path, augmentations=None, image_shape=(256, 256), channels=\"RGB\"):\n",
        "        self.__images_labels = []\n",
        "        self.image_shape = image_shape\n",
        "        self.channels = channels\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            self.labels = os.listdir(path)\n",
        "            for label in self.labels:\n",
        "                label_path = os.path.join(path, label)\n",
        "                if os.path.isdir(label_path):\n",
        "                    files = os.listdir(label_path)\n",
        "                    for file in files:\n",
        "                        if file.endswith(\"jpg\") or file.endswith(\"png\"):\n",
        "                            image_path = os.path.join(label_path, file)\n",
        "                            self.__images_labels.append((image_path, label))\n",
        "                        else:\n",
        "                            pass\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def _load(self, path, channels=\"RGB\"):\n",
        "        width, height = self.image_shape\n",
        "        loader = A.Compose([\n",
        "            A.Resize(width=width, height=height),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "        image_array = np.array(Image.open(path).convert(channels))\n",
        "        return loader(image=image_array)[\"image\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__images_labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label = self.__images_labels[index]\n",
        "        image = self._load(path)\n",
        "\n",
        "        if self.augmentations is not None:\n",
        "            image = image.permute(1, 2, 0).numpy()\n",
        "            image = self.augmentations(image=image)[\"image\"]\n",
        "\n",
        "        label = self.labels.index(label)\n",
        "\n",
        "        return Dict({\n",
        "            \"image\": image,\n",
        "            \"label\": label,\n",
        "        })\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    all_images, all_labels = [], []\n",
        "    for item in batch:\n",
        "        image = item.image\n",
        "        label = item.label\n",
        "\n",
        "        all_images.append(item.image.tolist())\n",
        "        all_labels.append(label)\n",
        "\n",
        "    return {\n",
        "        \"images\": torch.tensor(all_images),\n",
        "        \"labels\": torch.tensor(all_labels, dtype=torch.int8)\n",
        "    }"
      ],
      "metadata": {
        "id": "3V7CN-0KRRuj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "zVcc3uHh51NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PlantDiseaseDataset(path=config.train_path,\n",
        "                                    image_shape=train_config.image_shape,\n",
        "                                    channels=train_config.image_channels)"
      ],
      "metadata": {
        "id": "L19PtgSfYj3D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(config.train_path)\n",
        "print(os.path.exists(config.train_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYyY_bRD6PxQ",
        "outputId": "fc3c8d5d-f3b2-4a84-88f6-40df5e7f6b97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../input/plant-disease-recognition-dataset/Train/Train\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pathes = [os.path.join(config.train_path, label) for label in train_dataset.labels]\n",
        "label_files = [os.listdir(path) for path in label_pathes]\n",
        "amount = [len(files) for files in label_files]\n",
        "\n",
        "palette = sns.color_palette([\"#5FB924\", \"#AB4800\", \"#B2BBAC\"])\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot()\n",
        "ax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\n",
        "sns.barplot(x=train_dataset.labels, y=amount, palette=palette,  ec=\"#000\", linewidth=1.5, zorder=2, ax=ax)\n",
        "ax.xaxis.set_tick_params(labelsize=14, size=0, pad=10)\n",
        "ax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\n",
        "ax.set_yticks(list(range(0, 450, 50)))\n",
        "ax.set_title(f\"Classes Distribution\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.01)\n",
        "ax.set_xlabel(\"Classes\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "ax.set_ylabel(\"Count\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "hide_spines(ax)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "27C5Qocs57v4",
        "outputId": "ffb07229-e4a8-4e86-fce6-d2bd84ba1ff3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PlantDiseaseDataset' object has no attribute 'labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1365669936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_pathes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_pathes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"#5FB924\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#AB4800\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"#B2BBAC\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PlantDiseaseDataset' object has no attribute 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Dataset & Data Loaders"
      ],
      "metadata": {
        "id": "stQvlu7i6qbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PlantDiseaseDataset(path=config.train_path,\n",
        "                                    augmentations=train_config.augmentations,\n",
        "                                    image_shape=train_config.image_shape,\n",
        "                                    channels=train_config.image_channels)\n",
        "\n",
        "validation_dataset = PlantDiseaseDataset(path=config.validation_path,\n",
        "                                         augmentations=train_config.augmentations,\n",
        "                                         image_shape=train_config.image_shape,\n",
        "                                         channels=train_config.image_channels)\n",
        "\n",
        "test_dataset = PlantDiseaseDataset(path=config.test_path,\n",
        "                                   augmentations=train_config.augmentations,\n",
        "                                   image_shape=train_config.image_shape,\n",
        "                                   channels=train_config.image_channels)\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=train_config.batch_size,\n",
        "                          num_workers=train_config.num_workers,\n",
        "                          pin_memory=True,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "validation_loader = DataLoader(dataset=validation_dataset,\n",
        "                               batch_size=train_config.batch_size*2,\n",
        "                               num_workers=train_config.num_workers,\n",
        "                               pin_memory=True,\n",
        "                               shuffle=False,\n",
        "                               collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=train_config.batch_size*2,\n",
        "                         num_workers=train_config.num_workers,\n",
        "                         pin_memory=True,\n",
        "                         shuffle=False,\n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zFp6s-A45-P4",
        "outputId": "f11d485c-c15a-4c93-b542-e6278497c118"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4020010444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                    \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                    channels=train_config.image_channels)\n\u001b[0;32m---> 15\u001b[0;31m train_loader = DataLoader(dataset=train_dataset, \n\u001b[0m\u001b[1;32m     16\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                           \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytnUixV26o_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}